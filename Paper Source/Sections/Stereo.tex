\subsection{Binocular Computer Stereo Vision}
In order to perceive depth the human eye uses many visual cues, both monocular and binocular. Of these visual cues, stereopsis, the perception of depth resulting from the brain comparing the differences in images produced by both eyes, is in many ways one of the easiest depth perceptions methods to mimic through software, as it is the least reliant on external sources of stimuli and human experience. This is what Stereo Computer Vision attempts to do; building depth maps by comparing scenes from multiple vantage points. More specifically Binocular Computer Stereo Vision does this by comparing the images from two cameras and by extracting and comparing common features from both images it builds a depth map of the scene in question.

\subsubsection{Removing Distortion from Images}
Modern cameras introduce two major kinds of distortion to their images: barrel distortion and tangential distortion. Barrel distortion, a form of radial distortion, is introduced due to the curvature of lenses and, as such, is more prominent in wider angle lenses. Barrel distortion causes objects toward the edges of the frame to appear smaller than objects in the middle of the frame, therefore creating a situation where distances in relation to the size of an object are nonlinear. Tangential distortion on the other hand is introduced due to the lens of a given camera not being properly aligned with the imaging sensor, causing some areas of the image to look larger than others, once again causing the relationship between size and distance to be nonlinear. However, since binocular computer vision requires that the distance-size relationship must remain consistent throughout an image to be able to accurately compare images from different positions, these distortions must be corrected for, in order to effectively allow our camera to mimic the perfect pinhole camera.

In order to correct for radial and tangential distortion, many models and formulas have been proposed and developed, but for the purpose of this paper we will be using formulas derived from the Brown-Conrady model. The formulas for correcting radial distortion read as follows, where r is the distance from the distortion center to a distorted point:

$$x_{corrected} = x(1+k_1 r^2 + k_2 r^4 + k_3 r^6)$$
$$y_{corrected} = x(1+k_1 r^2 + k_2 r^4 + k_3 r^6)$$

So a pixel (x, y) in the distorted image will be remapped to ($x_{corrected}$, $y_{corrected}$). The same is true in the following formulas for correcting tangential distortion:

$$x_{corrected} = x + (2p_1 x y + p_2(r^2 + 1x^2))$$
$$y_{corrected} = y + (p_1(r^2 + 2y^2) + 2p_2 x y)$$

In above formulas are five distortion parameters that must be seperately experimentally determined in order to correct the image: $k_1, k_2, p_1, p_2,\text{and } k_3$. In addition to these, a given camera's "camera matrix" must be determined, which is a set of intrinsic camera parameters such as focal length and optical centers. This information is determined experimentally, on a camera to camera basis, by taking multiple images of a grid of objects of known size, shape, and relation to each other and tuning these parameters until the corrected grid matches the actual grid.
\subsubsection{Finding the epiline of an Image}
\subsubsection{Feature detecting and matching}
\subsubsection{Creating a depth map}