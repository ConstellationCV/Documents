Of course, creating a three dimensional model of a space is not possible without knowing three dimensional information about the individual objects which are to be extracted from the two dimensional image and placed in the three dimensional scene. Constellation takes a slightly unconventional approach to this problem in that it implements the traditional approach it is trying to improve, a structure from motion pipeline. However, the goal of producing a long-run rapidly updating computationally inexpensive system is still being satisfied. While they are not practical in situations where large scenes containing many objects must be generated relatively fast, SFMs perform at acceptable levels for smaller datasets, as their complexity is exponential. Constellation only employs the comparatively slow SFMs at non time-crucial moments; when training the network to recognize an object. While training itself to recognize an object in that image, Constellation concurrently uses a structure from motion pipeline to construct a three dimensional model of that object and stores that model.

As explained in the background (2.2), structure from motion pipelines use a series of images of the same object from different perspectives to create the three dimensional model of something. The pipeline can either be presented with with the locations of the camera when the different pictures were taken, or it can use some computations to figure that for itself. Once it has established the locations from which each of the several images were taken, the pipeline extracts common anchor points by finding distinct and easily distinguishable features in every image, and then matching those anchor points from one view of the object to another in order to determine the location of that point in a three dimensional space, taking into account the difference in position within the images of those anchor points. Evidently, an SFM pipeline requires several images of an object in order to establish a 3D representation of the object, and Constellation achieves this by dissecting a video clip, which captured as many unique views of the object as possible, into a series of images, extracting precisely 2 images from each second of video. Not only will these images be useful in constructing that model of this object, they surve a second purpose as they are also used to train Constellation to detect the object in images.

 From these images, Constellation is able to emplot an SFM pipeline to generate a 3D representation of the object. Due to the sparing and time-sensitive use of SFMs described earlier, Constellation has already learned what the model of individual objects in a scene look like at the time when it has to construct a model of a full scene, and thus saves precious compute time while it is generating models of the full scene from a 2D image on the fly.