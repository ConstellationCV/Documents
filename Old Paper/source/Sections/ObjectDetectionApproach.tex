\subsubsection{Determining a Classificiation Model}
The central problem of detecting various features within an image is one of classification. There exist several different approaches or algorithms for classification, including decision trees, naive, bayes, and KNN. However, only two classification models stood out for our particular application of object recognition; support vector machines (SVMs), and neural networks. SVMs operate by determining an optimal classification line, which seperates training data of two different types into two distinct sections, and performs classification by determining which side of that line a set of input data falls. While SVMs have a higher accuracy in general, and are more tollerant to redundant and irrelevant attributes, they require on average three times more training samples to accurately classify features than neural networks, and still perform evenly with neural networks with regards to the speed of classification, speed of learning, and tolerance to highly interdependent attributes. This system's applications require rapidly updating environments, which thus require rapid computations and rapid training. These reasons make SVMs impractical for use in Constellation, which means the best choice for Constellation's object detection and classification approach was neural networks, which could easily be pretrained and then adjusted during operation. With neural networks identified as the best approach to classifying various features in an image, the problem of how to actually implement and use a neural network to perform this tasks presents itself. The approach to detecting objects in an image has three major steps; training, iteration, and classification.

\subsubsection{Effectively Implementing the Classifier}
As discussed earlier (3.1), during the construction of models of individual objects, a series of images are generated from videos of each of the objects. These same images can be used to train the neural network using the backpropagation algorithm presented in the background (2.3.3). Each of these training images are greyscaled and then broken down into an array of values between 0 and 1, 0 representing pixels which are completely dark, and 1 representing pixels which are completely white. This array is then fed forward through the neural network and then that output is backpropagated, training the network more with every image fed through. Once the network is trained, it can be used to find those features in an image. In reality, the second two steps of the object detection process, iteration and classification, mesh into one more general process. Given the height and width of the objects the network was trained on, Constellation iterates over the image in question and employs a "cookie cutter" strategy of cutting out smaller images of the size of the training images at regular intervals within the image, and checks each of these smaller images for the prescence of one of the objects the network was trained on. If the network's confidence that one of these images is present exceeds a set threshold value, the network classifies this "sub-image" as the location of the classified object.

\subsubsection{Narrowing Classifications While Maximizing Accuracy}

\subsubsection{Employing Universal AI Algorithms to Detect Both Objects and Laser Dots}
The same approach can be used to find the laser dots which, as discussed in the following sections, are quite vital to the distance estimation needed to construct the model of the scene. Several images of these dots were taken in various environments and a seperate network was trained on these images, using a similar approach as that of object classification. The training of the network used to detect the dots differs in that, instead of grayscaling the images as done in the other approach, colored images are considered, and instead of arrays of values between 0 and 1, the network is provided an array of arrays of red, green, blue (RGB) values. The classification of all the laser dots in an image is run then in the same manner as that of objects, and is run concurrently with that process, as both processes employ seperately trained networks and other resources.